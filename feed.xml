<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://yoharol.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://yoharol.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2026-02-07T21:49:35+00:00</updated><id>https://yoharol.github.io/feed.xml</id><title type="html">Yoharol’s Blog</title><subtitle>Do something interesting everyday. </subtitle><entry><title type="html">Write Summation as Matrix</title><link href="https://yoharol.github.io/blog/2023/LargeMatrix/" rel="alternate" type="text/html" title="Write Summation as Matrix"/><published>2023-05-01T00:00:00+00:00</published><updated>2023-05-01T00:00:00+00:00</updated><id>https://yoharol.github.io/blog/2023/LargeMatrix</id><content type="html" xml:base="https://yoharol.github.io/blog/2023/LargeMatrix/"><![CDATA[<p>It is hard to understand complex computation with summation of numerous symbols. Writing a linear system in matrix form can greatly help to get a high level perspective. However, building a matrix form can be brain burning.</p> <p>It is hard to clearify a general method for such formula conversion. In this blog I record some specific cases to remind myself what is the common routine and useful toolbox.</p> <h2 id="linear-blend-skinning">Linear Blend Skinning</h2> <p>LBS can be represented as</p> \[\mathbf{x}_i=\sum_{j}w_{ij}\mathbf{T}_j\begin{pmatrix}\mathbf{x}_i \\ 1\end{pmatrix}\] <p>which is a simple summation.</p> <p>Suppose $dim=3$, we want a matrix multiplication to cover all the $\mathbf{x}_i$ and $\mathbf{T}_j$.</p> <p>There are different ways to build such a matirx form. The first thing we need to figure out is which is the most important elements, and stack them into a matrix. Here we suppose the problem is to study affine transformation $\mathbf{T}_j$. To write $\mathbf{T}$ as the last element we first need to transpose the formula as</p> \[\mathbf{x}_i^T=\sum_j w_{ij}\begin{pmatrix}\mathbf{x}_i &amp; 1 \end{pmatrix}\mathbf{T}_j^T.\] <p>Stack all the transposed affine transformation into a large matrix</p> \[\mathbf{T}=\begin{pmatrix}\mathbf{T}_1\\\mathbf{T}_2\\\vdots\\\mathbf{T}_m\end{pmatrix}.\] <p>A summation is equal to an inner product, which can happen between two tensors of any dimensions. Here the inner product can be built between two matrix</p> \[\mathbf{X}'=\mathbf{M}\mathbf{T}\] <p>in which \(\mathbf{M}_j = \begin{pmatrix}w_{1j}(\mathbf{x}_1^T\ \ 1) &amp; \dots &amp; w_{nj}(\mathbf{x}_n^T \ \ 1)\end{pmatrix}\).</p> <p>On the other case, suppose we want to focus on studying vertex position $\mathbf{x}_i$. What will the matrix form be like? The answer is quite simple, so I just leave it here as an open question.</p> <h2 id="fast-mass-spring-system">Fast Mass Spring System</h2> <p>Now we consider a more complicated example. In this <a href="https://users.cs.utah.edu/~ladislav/liu13fast/liu13fast.html">paper</a> the incremental potential energy of the mass spring system is written as</p> \[g(x)=\sum_i \frac{1}{2}m_i \lVert\mathbf{x}_i-\mathbf{p}_i\rVert^2 + \sum_j \frac{1}{2}k_j\lVert\mathbf{x}_{j1}-\mathbf{x}_{j2}-\mathbf{d}_j\rVert^2\] <p>First we need to introduct matrix tools for square norm. There are 3 options. The first is to stack all vector into a long vector and compute the inner product. It is common and easy, but inelegant. The other two options are frobenius inner product and trace:</p> \[\mathbf{A}:\mathbf{B}=\langle \mathbf{A}, \mathbf{B} \rangle_{\text{F}}=\sum_{i,j}A_{ij}B_{ij} = \text{tr}(\mathbf{A}^T\mathbf{B})=\text{tr}(\mathbf{A}\mathbf{B}^T)\] <p>We want to study the vertex position $\mathbf{x}_i$ here. The first we need to do is to build the matrix</p> \[\mathbf{X}=\begin{pmatrix}\mathbf{x}_{11} &amp; \mathbf{x}_{12} &amp; \mathbf{x}_{13} \\ \vdots &amp; \vdots &amp; \vdots \\ \mathbf{x}_{n1} &amp; \mathbf{x}_{n2} &amp; \mathbf{x}_{n3}\end{pmatrix}\] <p>as the vertical stack of all position vectors. The sum of square norm is</p> \[\sum_i \lVert\mathbf{x}_i\rVert^2=\text{tr}(\mathbf{X}\mathbf{X}^T)\] <p>Now the problem is the term \(\mathbf{x}_{j1}-\mathbf{x}_{j2}-\mathbf{d}_j\). We set up a <em>selection matrix</em> as:</p> \[\begin{align*} \mathbf{x}_{j1}^T-\mathbf{x}_{j2}^T&amp;=\mathbf{G}_j^T\mathbf{X}\\ \mathbf{d}_j^T&amp;=\mathbf{S}_j^T\mathbf{D} \end{align*}\] <p>Then we have</p> \[\begin{align*} \sum_j \frac{1}{2}k_j\lVert\mathbf{x}_{j1}^T-\mathbf{x}_{j2}^T-\mathbf{d}_j^T\rVert^2&amp;=\sum_j\frac{1}{2}k_j\lVert\mathbf{G}^T_j \mathbf{X}-\mathbf{S}^T_j\mathbf{D}\rVert^2\\ &amp;= \sum_j \frac{1}{2}k_j\text{tr}\left((\mathbf{G}^T_j\mathbf{X}-\mathbf{S}^T_j\mathbf{D})^T(\mathbf{G}^T_j\mathbf{X}-\mathbf{S}^T_j\mathbf{D})\right)\\ &amp;=\text{tr}\left(\frac{1}{2}\mathbf{X}^T\left(\sum_jk_j\mathbf{G}_j\mathbf{G}_j^T\right)\mathbf{X}\right)-\text{tr}\left(\mathbf{X}^T\left(\sum_jk_j\mathbf{G}_j\mathbf{S}_j^T\right)\mathbf{D}\right)+\mathbf{C}\\ &amp;= \frac{1}{2}\text{tr}(\mathbf{X}^T\mathbf{L}\mathbf{X})-\text{tr}(\mathbf{X}^T\mathbf{J}\mathbf{D})+\mathbf{C}. \end{align*}\] <p>Notice that we ignore the constant term that is irrelavant to $\mathbf{X}$. The result reveals the true nature of this equation, and it is easy for us to further differentiate this formula.</p> <h3 id="trace-derivative">Trace Derivative</h3> <p>The most important fact about trace derivative is</p> \[\frac{\partial \text{tr}(\mathbf{X})}{\partial \mathbf{X}}=\mathbf{I}\] <p>or we can write it as</p> \[\delta \text{tr}(\mathbf{X})=\mathbf{I}:\delta\mathbf{X}\] <p>It is convenient to apply the consequent chain rule. However, the most convenient way is to write trace in the summation form and differentiate it directly.</p> <p>For example, we know that $\frac{\partial\mathbf{A}\mathbf{X}}{\partial \mathbf{X}}$ is a fourth-order tensor</p> \[\frac{\partial (\mathbf{A}\mathbf{X})_{ij}}{\partial X_{ab}}=\delta_{jb}A_{ia}\] <p>The trace $\text{tr}(\mathbf{A}\mathbf{X})=\sum_{i} (\mathbf{A}\mathbf{X})_{ii}$, so the derivative is</p> \[\frac{\partial\text{tr}(\mathbf{A}\mathbf{X})}{\partial X_{ab}}=\sum_i \delta_{ib}A_{ia}=A_{ba}\] <p>or simply</p> \[\frac{\partial \text{tr}(\mathbf{A}\mathbf{X})}{\partial \mathbf{X}}=\mathbf{A}^T.\] <p>Now we consider the quadratic form</p> \[\begin{align*} \frac{\partial \text{tr}(\mathbf{X}^T\mathbf{A}\mathbf{X})}{\partial\mathbf{X}_{ab}}&amp;=\frac{\partial }{\partial \mathbf{X}_{ab}}\left(\sum_{i,k,l}A_{kl}X_{ki}X_{li}\right)\\ &amp;=\sum_{l}A_{al}X_{lb}+\sum_k A_{ka}X_{kb}\\ \end{align*}\] <p>It is clear that the terms on the RHS is the matrix product, leads to</p> \[\frac{\partial\text{tr}(\mathbf{X}^T\mathbf{A}\mathbf{X})}{\partial \mathbf{X}}=(\mathbf{A}+\mathbf{A}^T)\mathbf{X}\] <p>For more example of matrix derivative, refer to this <a href="https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf">matrix cookbook</a>.</p> <p>Now let us go back to the fast mass spring system. The incremental potential energy is</p> \[g(x)=\frac{1}{2h^2}\text{tr}\left((\mathbf{X}-\mathbf{P})^T\mathbf{M}(\mathbf{X}-\mathbf{P})\right)+\frac{1}{2}\text{tr}(\mathbf{X}^T\mathbf{L}\mathbf{X})-\text{tr}(\mathbf{X}^T\mathbf{J}\mathbf{D})+\mathbf{C}.\] <p>Based on the knowledge in this section, it is easy to get the derivative</p> \[\frac{\partial g(x)}{\partial \mathbf{X}}=\frac{1}{h^2}\mathbf{M}(\mathbf{X}-\mathbf{P})+\mathbf{L}\mathbf{X}-\mathbf{J}\mathbf{D}\] <p>in which both $\mathbf{M}$ and $\mathbf{L}$ are symmetric matrix. To minimize it, we need to solve</p> \[(\frac{\mathbf{M}}{h^2}+\mathbf{L})\mathbf{X}=\frac{1}{h^2}\mathbf{M}\mathbf{P}+\mathbf{J}\mathbf{D}\] <p>The system matrix $\frac{\mathbf{M}}{h^2}+\mathbf{L}$ is symmetric, positive definite and constant, so we can solve it efficiently.</p>]]></content><author><name></name></author><category term="research"/><category term="note"/><summary type="html"><![CDATA[It is hard to understand complex computation with summation of numerous symbols. Writing a linear system in matrix form can greatly help to get a high level perspective. However, building a matrix form can be brain burning.]]></summary></entry><entry><title type="html">Inverse Kinematics</title><link href="https://yoharol.github.io/blog/2023/InverseKinematics/" rel="alternate" type="text/html" title="Inverse Kinematics"/><published>2023-03-15T00:00:00+00:00</published><updated>2023-03-15T00:00:00+00:00</updated><id>https://yoharol.github.io/blog/2023/InverseKinematics</id><content type="html" xml:base="https://yoharol.github.io/blog/2023/InverseKinematics/"><![CDATA[<p>In this article we discuss a simple but nontraditional exmaple of inverse kinematics.</p> <p>We have an object composed of vertices $\mathbf{x}_1, \mathbf{x}_2, \dots, \mathbf{x}_n\in\mathbb{R}^{dim}$($d=2$ or $3$) with corresponding rest pose position $\overline{\mathbf{x}}_1, \overline{\mathbf{x}}_2, \dots, \overline{\mathbf{x}}_n$. For convenience we concatenate all of positions into a vector $\mathbf{X}\in\mathbf{R}^{n\cdot\mathrm{dim}\times 1}$.</p> <p>A set of control points is specified $\mathcal{P}={\mathbf{P}_1, \mathbf{P}_2,\dots, \mathbf{P}_m}$. Practically the controllers come within shapes as points, bones and cages. We will discuss in the next section that they can all be translated as oriented control points with constriants. Each control points takes a rotation $\mathbf{R}_i$ and a translation $\mathbf{d}_i$. In the rest pose we define $\mathbf{\overline{R}}_i=\mathbf{I}$, and translation $\mathbf{\overline{d}}_i$.</p> <p>State of each control point can be represented by $s$ parameters, which means that $s$ is the degrees of freedom. We summarize all of parameters that reprensent the degrees of freedom of control points into a long vector $\mathbf{\theta}\in\mathbb{R}^{m\cdot s\times 1}$</p> <p>We focus on standard linear blend skinning(LBS) method. The rigged position $\mathbf{x}^r_1, \mathbf{x}^r_2,\dots, \mathbf{x}^r_n$ is manipulated by weighted linear combination of transformations of all control points:</p> \[\mathbf{x}_i^r=\sum_{j=1}^m w_{ij}\left[\mathbf{R}_j(\mathbf{\overline{x}}_i-\overline{\mathbf{d}}_j)+\mathbf{d}_j\right]\] <p>Or we can say that the rigged position $\mathbf{X}^r$ is controlled by parameter set $\theta$ as $\mathbf{X}^r=\mathbf{X}^r(\theta)$.</p> <p>Now given positions of vertices $\mathbf{X}$. Denote the mass matrix as $\mathbf{M}=\mathrm{diag}(m_1, m_2, \dots, m_n)\otimes \mathbf{I}^{\mathrm{dim}\times\mathrm{dim}}$. We can define the error between given positions and rigged positions as a quadratic form:</p> \[\ \ \ g(\theta)=\frac{1}{2}\big(\mathbf{X}-\mathbf{X}^r(\theta)\big)^T\mathbf{M}\big(\mathbf{X}-\mathbf{X}^r(\theta)\big)\] <p>We would like to find the best pose of controllers to fit the given shape, with the precondition that we have aleady been given a parameter set $\theta$ that makes $g(\theta)$ small enough. This can be written as a minimization problem:</p> \[\theta_0= \underset{\mathbf{\theta}}{\operatorname{argmin}}\ \ g(\theta)\] <p>This problem can be solved seperately and iteratively:</p> <ol> <li>Fix rotation, find optimized translation $\mathbf{d}_1, \mathbf{d}_2, \dots, \mathbf{d}_n$</li> <li>Fix translation, find optimized rotation $\mathbf{R}_1, \mathbf{R}_2, \dots, \mathbf{R}_n$</li> </ol> <h2 id="find-optimized-translation">Find Optimized Translation</h2> <p>Suppose the rotation of each control point is fixed. Then we have:</p> \[\mathbf{x}^r_i=\sum_{j=1}^m w_{ij}\mathbf{R}_j(\mathbf{\overline{x}}_i-\mathbf{\overline{d}}_i)+\sum_{j=1}^m w_{ij}\mathbf{d}_j\] <p>Just as how we define $\mathbf{X}$, we can compress translations of all cntrol points into a long vector $\mathbf{d}\in\mathbb{R}^{\mathrm{dim}\cdot m\times 1}$. Related weights can be summarized into a weight matrix $\mathbf{W}=[w_{ij}]\otimes\mathbf{I}^{\mathrm{dim}\times\mathrm{dim}}$. Then eq. [?] can be written in a matrix form:</p> \[\mathbf{X}^r = \mathbf{X}^r_{\mathbf{R}}+\mathbf{W}\mathbf{d}\] <p>We substitute this linear matrix multiplication into $g(\theta)$. In our method the inverse kinematics step is performed in each time step. It is reasonable to take parameter from previous time step as the initial state \(\mathbf{d}_{t-1}\), and denote translation in current time step as \(\mathbf{d}_{t}=\mathbf{d}_{t-1}+\delta\mathbf{d}\) . With a new vector defined as $\mathbf{X}’=\mathbf{X}-\mathbf{X}^r_R-\mathbf{W}\mathbf{d}_{t-1}$ , the optimization problem get much simpler:</p> \[\ \ \ g(\mathbf{d})=\frac{1}{2}\big(\mathbf{X}'-\mathbf{W}\delta\mathbf{d}\big)^T\mathbf{M}\big(\mathbf{X}'-\mathbf{W}\delta\mathbf{d}\big)\] <p>Now we consider constraints. We suppose that all types of constraints can be denoted as $C(\mathbf{d})=0$, and $C$ is linear. Take a rigid bone as a common exmaple. the distance between two control points should be a constant. Which means that if control point $i$ and $j$ is connected by a control point, then we have a constraint function:</p> \[C=||\mathbf{d}_i-\mathbf{d}_j||-l_{ij}=0\] <p>This constraint is nonlinear. However, since we have already fixed the direction of all control points, then the distance constraint is equivalent to a linear constraint:</p> \[C=\delta\mathbf{d}_i-\delta\mathbf{d}_j=0\] <p>Another common constraint happens when a control point $\mathbf{d}_j$ is fully governed by users. It simply equals to $\delta\mathbf{d}_j=0$.</p> <p>Combining all of these linear constraints together, we have a minimization problem constrained by a linear system with constant coefficients:</p> \[\begin{align*} \text{Minimize}&amp;\ \ \ \frac{1}{2}\big(\mathbf{X}'-\mathbf{W}\delta\mathbf{d}\big)^T\mathbf{M}\big(\mathbf{X}'-\mathbf{W}\delta\mathbf{d}\big)\\ \text{subject to}&amp;\ \ \ \mathbf{G}\delta\mathbf{d}=0 \end{align*}\] <p>Then by the lagrangian multiplier method, we get a linear system to solve:</p> \[\begin{bmatrix} \mathbf{W}^T\mathbf{M}\mathbf{W} &amp; \mathbf{G}^T\\ \mathbf{G} &amp; 0 \end{bmatrix} \begin{bmatrix} \delta\mathbf{d} \\ \lambda \end{bmatrix}= \begin{bmatrix} \mathbf{W}^T\mathbf{M}\mathbf{X}'\\ 0 \end{bmatrix}\] <p>Notice that coefficient on the left side is constant, symmetric and positive definite, so we can precompute its inverse matrix or Cholesky decomposition. Only the right side need to be updated.</p> <h2 id="find-optimized-rotation">Find Optimized Rotation</h2> <p>Now we assume that all translation of control points are fixed. Recall the term to be minimized:</p> \[g(\theta)=\frac{1}{2}\big(\mathbf{X}-\mathbf{X}^r(\theta)\big)^T\mathbf{M}\big(\mathbf{X}-\mathbf{X}^r(\theta)\big)\] <p>It is not convenient to subsitute rotation parameters into this formula. However, we can simplify its first order derivative:</p> \[g'(\theta)=\bigg(\frac{\partial \mathbf{X}^r(\theta)}{\partial \theta}\bigg)^T\mathbf{M}(\mathbf{X}-\mathbf{X}^r(\theta))\] <p>This term can be seperated row by row as:</p> \[g'_k=\sum_{i=1}^n m_i \big(\frac{\partial \mathbf{x}_i^r}{\partial \theta_k}\big)^T(\mathbf{x}_i-\mathbf{x}_i^r)\] <p>We first discuss the case in 3-dimentional space. As we mentioned before, the inverse kinematics is performed in each time step of a continuous physics simulation, and physics based dyanmics naturally require little time steps. It means that for all control points, change of states is minimum. Thus for rotation matrix from each control point $\mathbf{R}_j$, we can parameterize it by rotation vector $\mathbf{p}_j$. The first order derivative can be obtained by infinitestimal rotation as:</p> \[\frac{\partial\mathbf{R}_j(\mathbf{p}_j)\mathbf{u}}{\partial \mathbf{p}}=-[\mathbf{u}]_\times\] <p>The notation $[\mathbf{u}]_\times$ is a cross product matrix defined as follows:</p> \[[\mathbf{u}]_{\times}=\begin{bmatrix} 0 &amp; -u_z &amp; u_y\\ u_z &amp; 0 &amp; -u_x\\ -u_y &amp; u_x &amp; 0 \end{bmatrix}\] <p>In 2-dimentional case it will be a column vector:</p> \[[\mathbf{u}]_\times=\begin{pmatrix} u_y &amp; -u_x \end{pmatrix}^T\] <p>Then we can rewrite the first order derivative as:</p> \[\frac{\partial g(\mathbf{p})}{\partial \mathbf{p}_j} = \sum_{i=1}^n m_iw_{ij}[\mathbf{\overline{d}}_j-\mathbf{\overline{x}}_i]_\times ^T (\mathbf{x}_i-\mathbf{x}^r_i)\] <p>We perform a linear search in direction of first order derivative. Once we get the infinitestimal rotation vector $\delta\mathbf{p}_j$, rotation of control point $j$ will be updated by \(\mathbf{R}_j(\mathbf{p}_j+\delta\mathbf{p}_j)=(\mathbf{I}+[\mathbf{p}_j]_\times)\mathbf{R}_j\).</p> <p>For hierarchical structure skeleton, the translation of child node is decided by rotation and translation of parent node. If such structure exist, we update related control points in a specified order, from root to leaves. Every time we are updating the rotation matrix, we also update the translation of all related children if it is part of the hierarchical structure.</p> <p>We summarize our inverse kinematics algorithm as follows:</p> <ol> <li>Fix the rotation, find optimized translation for all control points</li> <li>Fix the translation, find optimized infiniestimal rotation vector for all control points.</li> <li>Update rotation matrix and translation of related children</li> </ol>]]></content><author><name></name></author><category term="research"/><category term="note"/><summary type="html"><![CDATA[In this article we discuss a simple but nontraditional exmaple of inverse kinematics.]]></summary></entry><entry><title type="html">Representations of Rotation and Derivation</title><link href="https://yoharol.github.io/blog/2023/Rotation/" rel="alternate" type="text/html" title="Representations of Rotation and Derivation"/><published>2023-02-01T00:00:00+00:00</published><updated>2023-02-01T00:00:00+00:00</updated><id>https://yoharol.github.io/blog/2023/Rotation</id><content type="html" xml:base="https://yoharol.github.io/blog/2023/Rotation/"><![CDATA[<p>It is hard to represent rotation, either in formula of Euler Angles or Quaternions. There are only three DOF in a rotation, and we need to find a good representation such that we can get derivatives wrp. to 3 individual parameters.</p> <p>In this article, axis-angle representation will be used. we first introduce 3 formulas, they are actucally identical. Then, we will choose one of it to get the derivatives.</p> <h2 id="axis-angle-representation">Axis-Angle Representation</h2> <p>Axis-angle representation, or more concisely the <strong>rotation vector</strong>, is a vector $\mathbf{v}$ in $\mathbb{R}^3$ space. It represents a rotation of angle $\theta=|\mathbf{v}|$ along the axis $\mathbf{\hat{e}}=\mathbf{\hat{v}}$.</p> <p align="center"> <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/7/7b/Angle_axis_vector.svg/800px-Angle_axis_vector.svg.png" alt="drawing" width="120"/> </p> <p>What we want is a rotation matrix $\mathbf{R}(\mathbf{v})$ from it. There are 3 formulas:</p> <ol> <li>Rodrigues’ rotation formula(Vector notation)</li> <li>Rodrigues’ rotation formula(Matrix notation)</li> <li>Exponential Map</li> </ol> <h3 id="rodrigues-rotation-formula">Rodrigues’ rotation formula</h3> <p>Suppose we have a vector $\mathbf{u}$, and a rotation vector $\mathbf{v}$. We can seperate $\mathbf{u}$ into 2 components: $(\mathbf{u}\cdot\mathbf{\hat{v}})\mathbf{\hat{v}}$, $\mathbf{u}-(\mathbf{u}\cdot\mathbf{\hat{v}})\mathbf{\hat{v}}$. Perpendicular to these 2 components, there is the third direction $\mathbf{\hat{v}}\times\mathbf{\hat{u}}$.</p> <p>It is easy to see that:</p> \[\begin{align*} \mathbf{R}\mathbf{u}&amp;=(\mathbf{u}\cdot\mathbf{\hat{v}})\mathbf{\hat{v}} + \cos\theta (\mathbf{u}-(\mathbf{u}\cdot\mathbf{\hat{v}})\mathbf{\hat{v}})+\sin\theta \mathbf{v}\times\mathbf{u}\\ &amp;=\mathbf{u}\cos\theta+(\mathbf{\hat{v}}\times\mathbf{u})\sin\theta+(1-\cos\theta)(\mathbf{u}\cdot\mathbf{\hat{v}})\mathbf{\hat{v}} \end{align*}\] <p>However, cross product can always cause headache. With this formula, we still do not know what is the rotation matrix $\mathbf{R}$.</p> <p>To get rid of the cross product, We can define a <strong>cross product matrix</strong> as follows:</p> \[\mathbf{V}=[\mathbf{v}]_{\times}=\begin{bmatrix} 0 &amp; -v_z &amp; v_y\\ v_z &amp; 0 &amp; -v_x\\ -v_y &amp; v_x &amp; 0 \end{bmatrix}\] <p>Such that $\mathbf{v}\times\mathbf{u}=[\mathbf{\hat{v}} ]_\times\mathbf{u}$.</p> <p>We can write Rodrigues’ rotation formula in a more elegant way:</p> \[\mathbf{R}\mathbf{u}=\mathbf{u}+\sin\theta[\mathbf{\hat{v}}]_\times\mathbf{u}+(1-\cos\theta)[\mathbf{\hat{v}}]_\times^2 \mathbf{u}\] <p>So we finally know what is the rotation matrix here:</p> \[\mathbf{R}=\mathbf{I}+\sin\theta\mathbf{V}+(1-\cos\theta)\mathbf{V}^2\] <h3 id="exponantial-map">Exponantial Map</h3> <p>Consider that we already have a rotation matrix $\mathbf{R}(\theta\mathbf{\hat{v}})$, and we do not know the actual formu of it. Now we rotate along the same axis $\mathbf{\hat{v}}$ with an infiniestimal angle $\varepsilon$. It should be:</p> \[\mathbf{R}((\theta+\varepsilon)\mathbf{\hat{v}})=\mathbf{R}(\varepsilon\mathbf{\hat{v}})\mathbf{R}(\theta\mathbf{\hat{v}})\] <p>According to Rodrigues’ rotation formula, when the rotation is small, we have:</p> \[\mathbf{R(\varepsilon\mathbf{\hat{v}})}=\mathbf{I}+\varepsilon[\mathbf{\hat{v}}]_\times\] <p>We can substitute it into the previous formula:</p> \[\mathbf{R}((\theta+\varepsilon)\mathbf{\hat{v}})=(\mathbf{I}+\varepsilon[\mathbf{\hat{v}}]_\times)\mathbf{R}(\theta\mathbf{\hat{v}})\] <p>So we have the derivative of rotation matrix to the rotation angle:</p> \[\begin{align*} \frac{\partial \mathbf{R}(\theta\mathbf{\hat{v}})}{\partial \theta} &amp;=\lim_{\varepsilon\to0}\frac{\mathbf{R}((\theta+\varepsilon)\mathbf{\hat{v}})-\mathbf{R}(\theta\mathbf{\hat{v}})}{\varepsilon} \\ &amp;=[\mathbf{\hat{v}}]_\times \mathbf{R}(\theta\mathbf{\hat{v}}) \end{align*}\] <p>This is a differentiable equation, with boundary $\mathbf{R}(0)=\mathbf{I}$. And we already know how to solve a differentiable equation like this. The answer is:</p> \[\mathbf{R}(\theta\mathbf{\hat{v}})=e^{[\mathbf{v}]_\times}=e^{\mathbf{V}}\] <p>With the knowledge that $\mathbf{V}^3=-\mathbf{V}$, we can prove that the exponential map is equivalent to the matrix form of Rodrigues’ rotation formula by taylor expansion.</p> <p>For further reading, chech this <a href="https://en.wikipedia.org/wiki/Axis%E2%80%93angle_representation">page</a>.</p> <h2 id="derivative-of-rotation-matrix">Derivative of Rotation Matrix</h2> <p>We have already know the rotation matrix from the rotation vector. The next step is, what is the derivative from the rotated vector to the rotation vector?</p> <p>More specifically, we need:</p> \[\lim_{|d\mathbf{v}|\to0}\frac{\mathbf{R}(\mathbf{v}+d\mathbf{v})\mathbf{u}-\mathbf{R}(\mathbf{v})\mathbf{u}}{dv_i}\] <p>We already know that:</p> \[\mathbf{R}(\mathbf{v}+d\mathbf{v})=\mathbf{R}(d\mathbf{v})\mathbf{R}(\mathbf{v})\] <p>So if we are trying to solve such as some optimization problems on $f(\mathbf{R}(\mathbf{v}^{(m)}))$ that derivatives are needed in each iteration, we only need derivative with new infinitestimal rotation vector $\mathbf{p}$ being at the identity:</p> \[\mathbf{J}:=\frac{\partial f(e^{[\mathbf{p}]_\times}\mathbf{R}(\mathbf{v}^{(m)}))}{\partial \mathbf{p}}\bigg|_{\mathbf{p}=0}\] <p>And the same for second order Hessian matrix $\mathbf{H}$. After having $\mathbf{p}$, we apply the update rule $\mathbf{R}(\mathbf{v}^{(m+1)})=e^{[\mathbf{p}]_\times}\mathbf{R}(\mathbf{v}^{(m)})$.</p> <h3 id="jacobian-of-rotation-matrix">Jacobian of Rotation Matrix</h3> <p>We already know that the cross product matrix can be written as:</p> \[[\mathbf{p}]_\times=\mathbf{G}_1 p_1+\mathbf{G}_2 p_2 + \mathbf{G}_3 p_3\] <p>In which $\mathbf{G}_i=[\mathbf{\hat{e}}_i]$. This is a linear combination, and the first order derivative is also obvious:</p> \[\frac{\partial [\mathbf{p}]_\times}{\partial \mathbf{p}}\bigg|_{\mathbf{p}=0}=\begin{bmatrix}\mathbf{G}_1 &amp; \mathbf{G}_2 &amp; \mathbf{G}_3\end{bmatrix}\] <p>Or we can write it in derivatives of each component:</p> \[\frac{\partial [\mathbf{p}]_\times}{\partial p_i}=[\mathbf{\hat{e}}_i]_\times\] <p>Since we know that $\mathbf{R}(\mathbf{p})=e^{[\mathbf{p}]_\times}$, then we have $\frac{\partial\mathbf{R}(\mathbf{p})}{\partial p_i}=[\mathbf{\hat{e}}_i] _\times$.</p> <p>However, we can make our live more easily to consider the derivate of rotated vector to rotation vector. First order derivative only needs first order terms in taylor expansion, which is:</p> \[\begin{align*} \mathbf{R}\mathbf{u}&amp;=\mathbf{u}+[\mathbf{p}]_\times \mathbf{u}\\ &amp;=\mathbf{u}-[\mathbf{u}]_\times \mathbf{p} \end{align*}\] <p>Such that we have:</p> \[\frac{\partial \mathbf{R}(\mathbf{p})\mathbf{u}}{\partial \mathbf{p}}\bigg|_{\mathbf{p}=0}=-[\mathbf{u}]_\times\] <h3 id="hessian-of-rotation-matrix">Hessian of Rotation Matrix</h3> <p>Still, we start with $\mathbf{R}(\mathbf{p})=e^{[\mathbf{p}]_\times}$. The second order Taylor expansion is:</p> \[\begin{align*} \mathbf{R}(\mathbf{p}) &amp;=\mathbf{I}+[\mathbf{p}]_\times+\frac{1}{2}[\mathbf{p}]_\times[\mathbf{p}]_\times\\ &amp;=\mathbf{I}+\sum_i \mathbf{G}_i p_i+\frac{1}{2}\sum_i\sum_j \mathbf{G}_i \mathbf{G}_j p_i p_j \end{align*}\] <p>Then each component of second order derivative is:</p> \[\frac{\partial^2 \mathbf{R}(\mathbf{p})}{\partial p_i\partial p_j}=\frac{1}{2}([\mathbf{\hat{e}}]_i [\mathbf{\hat{e}}]_j + [\mathbf{\hat{e}}]_j[\mathbf{\hat{e}}]_i)\] <p>Since we know the second order derivative is only related to second order term, we have:</p> \[\begin{align*} \frac{\partial^2 \mathbf{R}(\mathbf{p})\mathbf{u}}{\partial \mathbf{p}^2} &amp;=\frac{\partial^2 }{\partial \mathbf{p}^2}(\frac{1}{2}[\mathbf{p}]_\times[\mathbf{p}]_\times\mathbf{u})\\ &amp;=\frac{\partial^2 }{\partial \mathbf{p}^2}(\frac{1}{2}\mathbf{p}\times\mathbf{p}\times\mathbf{u})\\ &amp;=\frac{1}{2}\frac{\partial^2 }{\partial \mathbf{p}^2}((\mathbf{p}\cdot\mathbf{u})\mathbf{p}-(\mathbf{p}\cdot\mathbf{p})\mathbf{u}) \end{align*}\] <p>The result is a third order tensor:</p> \[(\frac{\partial^2 \mathbf{R}(\mathbf{p})\mathbf{u}}{\partial \mathbf{p}^2})_{i,jk}=\frac{\partial^2 (\mathbf{R}(\mathbf{p})\mathbf{u})_i}{\partial p_j \partial p_k}=\frac{1}{2}(\delta_{ij}u_k+\delta_{ik}u_j-2\delta_{jk}u_i)\] <p>Written in three Matrix:</p> \[\begin{align*} (\frac{\partial^2 \mathbf{R}(\mathbf{p})\mathbf{u}}{\partial \mathbf{p}^2})_{1}&amp;=\begin{pmatrix}0 &amp; u_y &amp; u_z\\ u_y &amp; -2u_x &amp; 0 \\ u_z &amp; 0 &amp; -2u_x \end{pmatrix}\\ (\frac{\partial^2 \mathbf{R}(\mathbf{p})\mathbf{u}}{\partial \mathbf{p}^2})_{2}&amp;=\begin{pmatrix}-2u_y &amp; u_x &amp; 0\\ u_x &amp; 0 &amp; u_z \\ 0 &amp; u_z &amp; -2u_y \end{pmatrix}\\ (\frac{\partial^2 \mathbf{R}(\mathbf{p})\mathbf{u}}{\partial \mathbf{p}^2})_{3}&amp;=\begin{pmatrix}-2u_z &amp; 0 &amp; u_x\\ 0 &amp; -2u_z &amp; u_y \\ u_x &amp; u_y &amp; 0 \end{pmatrix} \end{align*}\] <p>We can check if these 2 formulas by applying the chain rule:</p> \[\frac{\partial^2 (\mathbf{R}(\mathbf{p})\mathbf{u})_i}{\partial p_j \partial p_k}=\sum_s (\frac{\partial^2 \mathbf{R}(\mathbf{p})}{\partial p_j\partial p_k})_{is}u_s\]]]></content><author><name></name></author><category term="research"/><category term="note"/><summary type="html"><![CDATA[It is hard to represent rotation, either in formula of Euler Angles or Quaternions. There are only three DOF in a rotation, and we need to find a good representation such that we can get derivatives wrp. to 3 individual parameters.]]></summary></entry><entry><title type="html">Assembly Language and Language C</title><link href="https://yoharol.github.io/blog/2021/SSH-test/" rel="alternate" type="text/html" title="Assembly Language and Language C"/><published>2021-12-05T00:00:00+00:00</published><updated>2021-12-05T00:00:00+00:00</updated><id>https://yoharol.github.io/blog/2021/SSH%20test</id><content type="html" xml:base="https://yoharol.github.io/blog/2021/SSH-test/"><![CDATA[<h1 id="assembly-language-and-language-c">Assembly Language and Language C</h1> <h2 id="write-assembly-code">Write assembly code</h2> <p>First, make sure that both nasm and gcc are installed. There are few more libraries required.</p> <p>Then, create an assembly code file. For example, test.asm:</p> <pre><code class="language-assembly">global main

main:
	mov ebx, [x]
	add ebx, [y]
	mov eax, ebx
	ret

section .data
x dw 2
y dw 12
</code></pre> <p>Then, compile and run this code:</p> <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>nasm <span class="nt">-f</span> elf test.asm <span class="nt">-o</span> test.o
gcc <span class="nt">-m32</span> test.o <span class="nt">-o</span> <span class="nb">test</span>
./test<span class="p">;</span> <span class="nb">echo</span> <span class="nv">$?</span>
</code></pre></div></div> <p>Notice that command the return value of previous main function is automatically stored as “$?”.</p> <h2 id="from-c-language-to-assembly-language">From C Language to Assembly Language</h2> <p>We can use gdb debug tool to get assembly code of a program.</p> <p>First, we have a simple program, clanguage.c:</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="nf">main</span><span class="p">()</span>
<span class="p">{</span>
    <span class="kt">int</span> <span class="n">x</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="n">x</span> <span class="o">+=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div> <p>Then, compile it with a compiler you like, and let gdb open the generated program:</p> <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>clang clanguage.c <span class="nt">-o</span> assembly
gdb assembly
</code></pre></div></div> <p>While GDB is running, use the disassembly command to get assembly code of corresponding function:</p> <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">set </span>disassembly-flavor intel
disas main
</code></pre></div></div> <p>The following program should be shown:</p> <pre><code class="language-assembly">   0x0000000000401110 &lt;+0&gt;:	push   rbp
   0x0000000000401111 &lt;+1&gt;:	mov    rbp,rsp
   0x0000000000401114 &lt;+4&gt;:	mov    DWORD PTR [rbp-0x4],0x0
   0x000000000040111b &lt;+11&gt;:	mov    DWORD PTR [rbp-0x8],0x1
   0x0000000000401122 &lt;+18&gt;:	mov    eax,DWORD PTR [rbp-0x8]
   0x0000000000401125 &lt;+21&gt;:	add    eax,0x2
   0x0000000000401128 &lt;+24&gt;:	mov    DWORD PTR [rbp-0x8],eax
   0x000000000040112b &lt;+27&gt;:	mov    eax,DWORD PTR [rbp-0x8]
   0x000000000040112e &lt;+30&gt;:	pop    rbp
   0x000000000040112f &lt;+31&gt;:	ret 
</code></pre> <p>## “mov” and “lea”</p> <p>First we introduce a simple program:</p> <pre><code class="language-assembly">global main

main:
	add ebx, [y]
	lea eax, [x+2]
	mov eax, [eax]
	lea eax, [eax + 12]
	ret

section .data
x dw 2
y dw 12
</code></pre> <p>Try to write down the return value of this program without running it. The result should be <strong>24</strong>.</p> <p>The main problem is to distinguish the following commands:</p> <pre><code class="language-assembly">mov eax, ebx   ; eax = ebx
mov eax, [ebx] ; eax = ValueOnAddress(ebx)
lea eax, ebx   ; error
lea eax, [ebx+2] ; eax = ebx + 2
; If ebx is a value, eax=ebx+2, eax is also a value
; If ebx is an address, eax=ebx+2, eax is also a value 
</code></pre> <p>To conclude, “lea” is a “pure copy”, meanwhile “mov foo [foo]” will automatically analyze the address and get the value on that address.</p> <p>So we can look closer to the program we gave in the opening of this section:</p> <pre><code class="language-assembly">global main

main:
	add ebx, [y]
	; get value on address y, add it to ebx
	lea eax, [x+2]
	; x is an address, so eax stores an address now, which is y(y=x+2)
	mov eax, [eax]
	; Get the value on address eax and copy it to eax
	lea eax, [eax + 12]
	; eax = eax + 12
	ret

section .data
x dw 2
y dw 12
</code></pre> <h2 id="ptr-in-c-and-assembly">PTR in C and Assembly</h2> <p>Now we can know what is a “variable”, and what is a “ptr” by looking into the assembly code. Here’s a simple C program and corresponding assembly code:</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="nf">main</span><span class="p">()</span>
<span class="p">{</span>
    <span class="kt">int</span> <span class="n">x</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="n">x</span> <span class="o">+=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="kt">int</span> <span class="o">*</span><span class="n">y</span> <span class="o">=</span> <span class="o">&amp;</span><span class="n">x</span><span class="p">;</span>
    <span class="o">*</span><span class="n">y</span> <span class="o">+=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div> <pre><code class="language-assembly">push   rbp
mov    rbp,rsp
mov    DWORD PTR [rbp-0x4],0x0
mov    DWORD PTR [rbp-0x8],0x1
mov    eax,DWORD PTR [rbp-0x8]
add    eax,0x2
mov    DWORD PTR [rbp-0x8],eax
lea    rcx,[rbp-0x8]
mov    QWORD PTR [rbp-0x10],rcx
mov    rcx,QWORD PTR [rbp-0x10]
mov    eax,DWORD PTR [rcx]
add    eax,0x2
mov    DWORD PTR [rcx],eax
mov    eax,DWORD PTR [rbp-0x8]
pop    rbp
ret   
</code></pre> <p>First, create a variable “x”, set its value and operate on it:</p> <pre><code class="language-assembly">mov    DWORD PTR [rbp-0x8],0x1  ; x = 1
mov    eax,DWORD PTR [rbp-0x8]  ; eax = x
add    eax,0x2                  ; eax += 2
mov    DWORD PTR [rbp-0x8],eax  ; x = eax
</code></pre> <p>Then, ser a ptr “y” and point it to x:</p> <pre><code class="language-assembly">lea    rcx,[rbp-0x8]            ; rcx = address(x)
mov    QWORD PTR [rbp-0x10],rcx ; y = rcx = address(x)
mov    rcx,QWORD PTR [rbp-0x10] 
; rcx = ValueOnAddress[rbp-0x10]=address(x)
mov    eax,DWORD PTR [rcx]      
; eax = ValueOnAddress(rcx)=x
add    eax,0x2					; eax += 2
mov    DWORD PTR [rcx],eax      ; rcx = eax
ret                             ; return eax
</code></pre> <h2 id="array-in-c-and-assembly">Array in C and Assembly</h2> <p>Now let’s check how C create an array:</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="nf">main</span><span class="p">()</span>
<span class="p">{</span>
    <span class="kt">int</span> <span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">];</span>
    <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">];</span>
<span class="p">}</span>
</code></pre></div></div> <pre><code class="language-assembly">push   rbp
mov    rbp,rsp
mov    DWORD PTR [rbp-0x4],0x0
mov    DWORD PTR [rbp-0xc],0x1  ;x[0]=1
mov    DWORD PTR [rbp-0x8],0x2  ;x[1]=2
mov    eax,DWORD PTR [rbp-0x8] 
add    eax,0x2
mov    DWORD PTR [rbp-0x8],eax  ;x[1]+=2
mov    eax,DWORD PTR [rbp-0x8]
pop    rbp
ret   
</code></pre> <p>So an array is simply consecutive addresses.</p>]]></content><author><name></name></author><category term="blog"/><category term="note"/><summary type="html"><![CDATA[Assembly Language and Language C]]></summary></entry><entry><title type="html">Note: Pointer in C++</title><link href="https://yoharol.github.io/blog/2021/Pointers-in-Cpp/" rel="alternate" type="text/html" title="Note: Pointer in C++"/><published>2021-07-07T00:00:00+00:00</published><updated>2021-07-07T00:00:00+00:00</updated><id>https://yoharol.github.io/blog/2021/Pointers%20in%20Cpp</id><content type="html" xml:base="https://yoharol.github.io/blog/2021/Pointers-in-Cpp/"><![CDATA[<p>Every time I studied about pointers in C++, it soon got forgot and became confusing again after a period of time because it’s totally replaced in other programming languages. I’ll especially create a post about it for future review.</p> <p>C++ used call-by-value as default. When we clarify a new variable, it’s actually an address, and value stored in corresponding address.</p> <div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="n">a</span><span class="o">=</span><span class="mi">10</span><span class="p">;</span>
<span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"address of variable is "</span> <span class="o">&lt;&lt;</span> <span class="o">&amp;</span><span class="n">a</span> <span class="o">&lt;&lt;</span> <span class="s">" and value in this address is "</span> <span class="o">&lt;&lt;</span> <span class="n">a</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="n">TestClass</span> <span class="n">b</span><span class="p">;</span>
<span class="n">b</span><span class="p">.</span><span class="n">setValue</span><span class="p">(</span><span class="mi">10</span><span class="p">);</span>
<span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"address of class is "</span> <span class="o">&lt;&lt;</span> <span class="o">&amp;</span><span class="n">b</span> <span class="o">&lt;&lt;</span> <span class="s">" and value in this address is "</span> <span class="o">&lt;&lt;</span> <span class="n">b</span><span class="p">.</span><span class="n">getValue</span><span class="p">()</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
</code></pre></div></div> <p>Pointer is a more “raw” variable, it’s a variable that stores address in it. So <strong>a pointer is equal to the address of a variable</strong>.</p> <div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span><span class="o">*</span> <span class="n">pointer_int</span> <span class="o">=</span> <span class="o">&amp;</span><span class="n">a</span><span class="p">;</span>
<span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"address of variable is "</span> <span class="o">&lt;&lt;</span> <span class="n">pointer_int</span> <span class="o">&lt;&lt;</span> <span class="s">" and value in this address is "</span> <span class="o">&lt;&lt;</span> <span class="o">*</span><span class="n">pointer_int</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="n">TestClass</span><span class="o">*</span> <span class="n">pointer_class</span> <span class="o">=</span> <span class="o">&amp;</span><span class="n">b</span><span class="p">;</span>
<span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"address of class is "</span> <span class="o">&lt;&lt;</span> <span class="n">pointer_class</span> <span class="o">&lt;&lt;</span> <span class="s">" and value in this address is "</span> <span class="o">&lt;&lt;</span> <span class="n">pointer_class</span><span class="o">-&gt;</span><span class="n">getValue</span><span class="p">()</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
</code></pre></div></div> <p>By pointer, we can better understanding array in C++. When we clarify an array of length n, we actually clarify successive n addresses and create a pointer to the first address.</p> <div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="n">a</span><span class="p">[</span><span class="mi">10</span><span class="p">];</span>
<span class="kt">int</span><span class="o">*</span> <span class="n">b</span> <span class="o">=</span> <span class="k">new</span> <span class="kt">int</span><span class="p">[</span><span class="mi">10</span><span class="p">];</span> <span class="c1">//allocate n successive values to b</span>
<span class="n">a</span><span class="p">[</span><span class="mi">5</span><span class="p">]</span><span class="o">=</span><span class="mi">12</span><span class="p">;</span>
<span class="o">*</span><span class="p">(</span><span class="n">b</span><span class="o">+</span><span class="mi">5</span><span class="p">)</span><span class="o">=</span><span class="mi">12</span><span class="p">;</span>
<span class="c1">// a and b is equivalent, and a is a pointer</span>
<span class="c1">// which also means that: a[5] == *(a+5)</span>
</code></pre></div></div> <p>So to dynamically create a 2d array in C++, first we need to create an array of n pointers, and then for each pointer we allocate m successive addresses.</p> <div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span><span class="o">*</span> <span class="n">example</span> <span class="o">=</span> <span class="k">new</span> <span class="kt">int</span><span class="p">[</span><span class="n">n</span><span class="p">];</span> <span class="c1">//allocate n values to example</span>
<span class="kt">int</span><span class="o">**</span> <span class="n">a</span> <span class="o">=</span> <span class="k">new</span> <span class="kt">int</span><span class="o">*</span><span class="p">[</span><span class="n">n</span><span class="p">];</span> <span class="c1">//allocate n pointers to a</span>
<span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="n">i</span><span class="o">&lt;</span><span class="n">n</span><span class="p">;</span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
    <span class="o">*</span><span class="p">(</span><span class="n">a</span><span class="o">+</span><span class="n">i</span><span class="p">)</span> <span class="o">=</span> <span class="k">new</span> <span class="kt">int</span><span class="p">[</span><span class="n">m</span><span class="p">];</span>  <span class="c1">//actually we can allocate different length of array for each pointer</span>
<span class="c1">// *(*(a+1)+2) == a[1][2]</span>
</code></pre></div></div> <p>An example to understand what’s actually C++ is doing, is to create a pointer to an existing 2d array.</p> <div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="n">a</span><span class="p">[</span><span class="n">n</span><span class="p">][</span><span class="n">m</span><span class="p">];</span>
<span class="kt">int</span> <span class="n">example1</span><span class="p">[</span><span class="n">m</span><span class="p">];</span> <span class="c1">//In this clause, we create a pointer to an array of m elements.</span>
<span class="kt">int</span><span class="o">*</span> <span class="n">example2</span><span class="p">;</span> <span class="c1">//In this clause, we create a pointer to a value of int.</span>
<span class="kt">int</span><span class="p">(</span><span class="o">*</span><span class="n">p</span><span class="p">)[</span><span class="n">m</span><span class="p">];</span> <span class="c1">//So combine example1 and example2, we create a pointer of type int*, and this is a pointer to an array of m elements. </span>
<span class="n">p</span> <span class="o">=</span> <span class="n">a</span><span class="p">;</span>
<span class="c1">//*(*(p+1)+2) == a[1][2]</span>

</code></pre></div></div> <p>Why m should be clarified in the declaration of p? Because C++ needs to know <strong>What exactly a pointer is pointed to</strong>.</p> <p>In “int* p”, C++ knows that:</p> <ol> <li><em>p</em> is a pointer</li> <li>It’s pointed to an integer value</li> </ol> <p>So in “int(*p)[m]”, it also declare two things:</p> <ol> <li> <p><em>p</em> is a pointer</p> </li> <li> <p>It’s pointed to an array of <em>m</em> integers</p> </li> </ol> <p>That’s why this is incorrect:</p> <div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="n">a</span><span class="p">[</span><span class="n">n</span><span class="p">][</span><span class="n">m</span><span class="p">];</span>
<span class="kt">int</span><span class="o">**</span> <span class="n">p</span><span class="o">=</span><span class="n">a</span><span class="p">;</span>
</code></pre></div></div> <p>Because C++ already knows that <em>a</em> is a pointer to m values, however <em>p</em> is just a pointer to pointer. <em>a</em> and <em>p</em> have different data structure, but we can access the data in them with same method.</p>]]></content><author><name></name></author><category term="blog"/><category term="note"/><summary type="html"><![CDATA[Every time I studied about pointers in C++, it soon got forgot and became confusing again after a period of time because it’s totally replaced in other programming languages. I’ll especially create a post about it for future review.]]></summary></entry><entry><title type="html">Physics Based Animation: Elasticity, Lagrangian finite elements on linear tetrahedral meshes</title><link href="https://yoharol.github.io/blog/2021/Games202-lec3/" rel="alternate" type="text/html" title="Physics Based Animation: Elasticity, Lagrangian finite elements on linear tetrahedral meshes"/><published>2021-05-29T00:00:00+00:00</published><updated>2021-05-29T00:00:00+00:00</updated><id>https://yoharol.github.io/blog/2021/Games202-lec3</id><content type="html" xml:base="https://yoharol.github.io/blog/2021/Games202-lec3/"><![CDATA[<p>（unfinished）</p> <p>Prerequisite: Knowledge about mechanics of materials(<a href="https://www.youtube.com/c/TheEfficientEngineer/videos?view=0&amp;sort=dd&amp;flow=grid">helpful link</a>)</p> <p>Elastic materials are important because:</p> <ul> <li>Cool visual effects</li> <li>Not too hard to implement</li> <li>Base of other materials</li> </ul> <p>Deformation: A mapping function from rest material position to deformed material position.</p> <p>Deformation gradient <strong>F</strong>:</p> <p>Deform/rest volume ratio $J=det(\textbf{F})$</p> <p>Hyperelastic materials: materials whose stress-strain relationship is defined by a <strong>strain energy density function</strong>.</p> <ul> <li>Stress: Internal elastic forces to let material resotre original shape.</li> <li>Strain: Just replace it with deformation gradients <strong>F</strong> for now.</li> </ul> <h1 id="the-finite-element-method有限元">The Finite Element Method(有限元)</h1> <p>Linear tetrahedral(triangle) FEM</p> <p>affine transform</p> <p>F is constant within an element</p> <h1 id="advanced-reading">Advanced Reading</h1> <ul> <li>The classical FEM method and discretization methodology(<a href="http://www.femdefo.org/">link</a>)</li> <li>The Material Point Method for Simulating Continuum Materials(<a href="https://www.seas.upenn.edu/~cffjiang/research/mpmcourse/mpmcourse.pdf">link</a>)</li> <li></li> </ul>]]></content><author><name></name></author><category term="research"/><category term="note"/><summary type="html"><![CDATA[（unfinished）]]></summary></entry><entry><title type="html">Physics Based Animation: Mass Spring System</title><link href="https://yoharol.github.io/blog/2021/Games202-lec2/" rel="alternate" type="text/html" title="Physics Based Animation: Mass Spring System"/><published>2021-05-28T00:00:00+00:00</published><updated>2021-05-28T00:00:00+00:00</updated><id>https://yoharol.github.io/blog/2021/Games202-lec2</id><content type="html" xml:base="https://yoharol.github.io/blog/2021/Games202-lec2/"><![CDATA[<p>What’s Langrangian view and Eulerian view? How to turn a mass spring system into linear equations system, and how to solve it? What is the most advanced research on this topic?</p> <h1 id="langrangian-view-and-eulerian-view">Langrangian View and Eulerian View</h1> <p>拉格朗日 随波逐流</p> <p>Langrangian View: sensors that move passively with the simulated material</p> <p>“What are <strong>my position and velocity</strong>?”</p> <p>Mostly particle physics, position based. Every particle has position and velocity.</p> <p>欧拉视角 岿然不动</p> <p>Eulerian View: sensors that never move</p> <p>“What is the <strong>material velocity passing by</strong>?”</p> <p>In Eulerian View, the field like flow velocity is represented as a function of position and time.</p> <p>Related link: <a href="https://en.wikipedia.org/wiki/Lagrangian_and_Eulerian_specification_of_the_flow_field">Lagrangian and Eulerian specification of the flow field</a></p> <h1 id="mass-spring-system-easiest-analysis">Mass Spring System: Easiest Analysis</h1> <p>Mass spring system</p> \[\begin{align*} \vec{f_{ij}}&amp;=-k(||\vec{x}_i-\vec{x}_j||_2 - l_{ij})(\widehat{\vec{x}_i-\vec{x}_j})\\ \vec{f}_i&amp;=\sum^{j\neq i}_j\vec{f}_{ij}\\ \frac{\partial\vec{v}_i}{\partial t}&amp;=\frac{1}{m_i}\vec{f_i}\\ \frac{\vec{x}_i}{\partial t}&amp;=\vec{v}_i \end{align*}\] <p>$k$:spring stiffness; $l_{ij}$: spring rest length between particle i and particle j;</p> <p>To calculate, we have two ways to do it.</p> <p>Explicit:</p> <ul> <li>Future depends only on past</li> <li>Easy to implement</li> <li> <p>Easy to explode:</p> \[\Delta t\leq c\sqrt{\frac{m}{k}}(c\sim 1)\] </li> <li>Bad for stiff materials(k is too large)</li> </ul> <p><strong>The updating frequency should allow the system to get close to steady situation</strong>. Imagine a mass spring that the stiffness is too large, so the next frame the whole system already move past the steady point and get much far away in opposite direction, then the whole system will “explode”.</p> <p>Implicit:</p> <ul> <li>Future depends on <strong>both future and past</strong></li> <li>Need to solve a system of (linear) equations</li> <li>In general harder to implement</li> <li>Each step is more expensive but time steps are larger</li> <li>Numerical damping and locking.</li> </ul> <h1 id="solving-mass-spring-system">Solving Mass Spring System</h1> <p>To solve the whole system, there are three approaches:</p> <ol> <li> <p>Forward Euler(explicit)</p> \[\begin{align*} \vec{v}_{t+1}&amp;=\vec{v}_t + \Delta t\frac{\vec{f}_t}{m}\\ \vec{x}_{t+1}&amp;=\vec{x}_t + \Delta t\vec{v}_t \end{align*}\] </li> <li> <p>Semi-implicit Euler(aka. symplectic Euler, explicit, commonly used)</p> \[\begin{align*} \vec{v}_{t+1}&amp;=\vec{v}_t + \Delta t\frac{\vec{f}_t}{m}\\ \vec{x}_{t+1}&amp;=\vec{x}_t + \Delta t\vec{v}_{t+1} \end{align*}\] </li> <li> <p>Backward Euler(often with Newton’s method, implicit)</p> <p>$v_{t+1}$ relies to force $f(x_{t+1})$, we’ll use $M^{-1}$ as a abbreviation from position to force.</p> \[\begin{align*} \vec{x}_{t+1}&amp;=\vec{x}_t + \Delta t\vec{v_{t+1}}\\ \vec{v}_{t+1}&amp;=\vec{v}_t + \Delta t M^{-1}\vec{f}(\vec{x}_{t+1}) \end{align*}\] <p>This is a set of equations. To eliminate $\vec{x}_{t+1}$:</p> \[\vec{v}_{t+1} = \vec{v}_t + \Delta t M^{-1}f(\vec{x}_t + \Delta t\vec{v}_{t+1})\] <p>$M^{-1}$ is ordinarily not linear, so the equation is hard to solve. <strong>To linearize(one step of Newton’s method, which is a Taylor Expansion):</strong></p> \[\vec{v}_{t+1}=\vec{v}_t + \Delta t M^{-1}[\vec{f}{x_t} + \frac{\partial f}{\partial x}(x_t)\Delta t \vec{v}_{t+1}]\] <p>Clean it up, we finally get a linear equation:</p> \[[I-\Delta t^2 M^{-1}\frac{\partial f}{\partial x}(\vec{x}_t)] \vec{v}_{t+1} = \vec{v}_t + \Delta t M^{-1}f(\vec{x}_t)\] </li> </ol> <h1 id="solving-linear-system-jacobi-iterations">Solving Linear System: Jacobi Iterations</h1> <p>How to solve the linear system?</p> <ul> <li>Jacobi/Gauss-Seidel iterations (easy to implement)</li> <li>Conjugate gradients (later in this course)</li> </ul> <p>We’ll start with the Jacobi iterations. First, we’ll simplify the equation to a linear form:</p> \[\begin{align*} A&amp;=[I-\Delta t^2 M^{-1}\frac{\partial f}{\partial x}(x_t)]\\ b&amp;=v_t + \Delta tM^{-1}f(x_t) \end{align*}\] <p>Now we have a general linear equation $Av_{t+1}=b$. In Jacobi iterations, A can be decomposed into the sum of a diagonal component, a lower triangular part and an upper triangular part.</p> \[A = D + L + U\] \[D=\begin{bmatrix} a_{11} &amp; 0 &amp; \cdots &amp; 0 \\ 0 &amp; a_{22} &amp; \cdots &amp; 0 \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ 0 &amp; 0 &amp; \cdots &amp; a_{nn} \end{bmatrix}\] <p>Then we can build a ‘<strong>fake equalization</strong>’:</p> \[D x^{(k+1)} + (L+U)x^{(k)} = b\] <p>Find solution in an iteration process:</p> \[x^{(k+1)}=D^{-1}(b-(L+U)x^{(k)})\] <p>The minimum amount of storage is two vectors of size n. Jacobi iteration is useful because sometimes A is a <strong>sparse matrix</strong>, and $A^{-1}$ is hard to calculate, also may not be a sparse matrix anymore which requires much more storage. The process of Jacobi iteration use the original form of A without generate any other matrices.</p> <p>Note: Jacobi iteration does not always converge. We can easily prove that</p> \[v^{(k+1)}-v=D^{-1}(L+U)(v^{(k)}-v)\] <p>The <strong>condition of convergence</strong> is $\rho (D^{-1}(L+U))&lt;1$. Since we are discussing a sparse matrix, this condition seems apparently satisfied. For more information, check <a href="https://en.wikipedia.org/wiki/Jacobi_method#Convergence">here</a>.</p> <h1 id="advanced-reading">Advanced Reading</h1> <ul> <li>Smoothed-particle hydrodynamics(<a href="https://en.wikipedia.org/wiki/Smoothed-particle_hydrodynamics">SPH</a>)</li> <li>Weakly Cmpressible SPH(<a href="https://en.wikipedia.org/wiki/Smoothed-particle_hydrodynamics#Weakly_compressible_approach">WCSPH</a>) to simulate water</li> <li>SPH in computer graphics(<a href="https://people.inf.ethz.ch/~sobarbar/papers/Sol14/2014_EG_SPH_STAR_Presentation.pdf">Presentation</a>)</li> <li>SPH techniques for the physics based simulation of fluid and solids(<a href="https://interactivecomputergraphics.github.io/SPH-Tutorial/">Github Page</a>)</li> <li>Courant-Friedrichs-Lewy condition(<a href="https://en.wikipedia.org/wiki/Courant%E2%80%93Friedrichs%E2%80%93Lewy_condition">CFL</a>)</li> <li>Smoothed Particle Hydrodynamics (SPH) implemented with C++ and CUDA(<a href="https://github.com/TroyZhai/CPP-Fluid-Particles">Github Page</a>)</li> <li>Interlinked SPH Pressure Solvers for Strong Fluid-Rigid Coupling(C. Gissler et al.)</li> <li>耦合：两种不同的物理模拟系统能够双向交互</li> <li>From particles to Surfaces: Marching Cube, VDB</li> </ul> <p>Other partical-based simulation methods:</p> <ul> <li>Discrete element method(Particle based simulation for granular materials, 2005)</li> <li>Moving particle semi-implicit (Moving-particle semi-implicit method for fragmentation of incompressible fluid, 1996)</li> <li>Power Particles: An incompressible fluid solver based on power diagrams(Particles: an incompressible fluid solver based on power diagrams, 2015)</li> <li>A peridynamic perspective on spring-mass fracture(J. A. Levine et al.(2014))</li> </ul>]]></content><author><name></name></author><category term="research"/><category term="note"/><summary type="html"><![CDATA[What’s Langrangian view and Eulerian view? How to turn a mass spring system into linear equations system, and how to solve it? What is the most advanced research on this topic?]]></summary></entry><entry><title type="html">Note: Taichi</title><link href="https://yoharol.github.io/blog/2021/Taichi-Notes/" rel="alternate" type="text/html" title="Note: Taichi"/><published>2021-05-20T00:00:00+00:00</published><updated>2021-05-20T00:00:00+00:00</updated><id>https://yoharol.github.io/blog/2021/Taichi%20Notes</id><content type="html" xml:base="https://yoharol.github.io/blog/2021/Taichi-Notes/"><![CDATA[<p>Taichi is a high-performance language for computer graphics, and the creator of Taichi set up a tutorial course for it. This post is a record of some simple notes of Taichi.</p> <h1 id="tutorial-program-explained">Tutorial program explained</h1> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">taichi</span> <span class="k">as</span> <span class="n">ti</span>

<span class="n">ti</span><span class="p">.</span><span class="nf">init</span><span class="p">(</span><span class="n">arch</span><span class="o">=</span><span class="n">ti</span><span class="p">.</span><span class="n">cuda</span><span class="p">)</span>        
<span class="c1">#arch=ti.cpu, ti.gpu, ti.cuda, ti.opengl
</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">320</span>
<span class="n">pixels</span> <span class="o">=</span> <span class="n">ti</span><span class="p">.</span><span class="nf">field</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">n</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
<span class="c1"># a = ti.field(dtype=ti.f32, shape=(42, 63)) 
# tensor of 42*63 scalars
# b = ti.Vector.field(3, dtype=ti.f32, shape=4) 
# tensor of 4 * 3D vectors
# c = ti.Matrix.field(2, 2, dtype=ti.f32, shape=(3, 5)) 
# tensor of 3*5 2*2 matrices
# loss = ti.var(dtype=ti.f32, shape=()) 
# (0-D) tensor which is a single scalar
# b[2] = [3, 4, 5]
# loss[None] = 3
</span>
<span class="c1"># ti.Matrix can only be used for small matrix like 4*4
#Large matrix should be used as 2D tensor of scalars
# ti.Vector is the same as ti.Matrix but has only one column.
</span>
<span class="c1"># Now all var, vector and matrix is updated to field
</span>
<span class="c1"># Taichi function
# Can only be called by Taichi kernels and other Taichi functions
# Up to only one return argument 
</span><span class="nd">@ti.func</span>
<span class="k">def</span> <span class="nf">complex_sqr</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">ti</span><span class="p">.</span><span class="nc">Vector</span><span class="p">([</span><span class="n">z</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="o">-</span><span class="n">z</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">z</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">z</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="mi">2</span><span class="p">])</span>
    <span class="c1"># In taichi scope you can declear a vector 
</span>    <span class="c1"># by passing parameters as a list
</span>
<span class="c1"># Taichi kernel, complied just-in-time, statically-typed
# lexically-scoped, parallel and differentiable
# Kernel arguments and return values must be type-hinted
# Kernel can't be called by kernel
</span><span class="nd">@ti.kernel</span>
<span class="k">def</span> <span class="nf">paint</span><span class="p">(</span><span class="n">t</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">pixels</span><span class="p">:</span>    <span class="c1"># automatically parallelized for all i, j
</span>    <span class="c1">#struct-for loop, iterate over all tensor coordinates
</span>        <span class="n">c</span> <span class="o">=</span> <span class="n">ti</span><span class="p">.</span><span class="nc">Vector</span><span class="p">([</span><span class="o">-</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">ti</span><span class="p">.</span><span class="nf">cos</span><span class="p">(</span><span class="n">t</span><span class="p">)</span><span class="o">*</span><span class="mf">0.2</span><span class="p">])</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">ti</span><span class="p">.</span><span class="nc">Vector</span><span class="p">([</span><span class="n">i</span><span class="o">/</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">j</span><span class="o">/</span><span class="n">n</span><span class="o">-</span><span class="mf">0.5</span><span class="p">])</span> <span class="o">*</span> <span class="mi">2</span>
        <span class="n">iterations</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">while</span> <span class="n">z</span><span class="p">.</span><span class="nf">norm</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mi">20</span> <span class="ow">and</span> <span class="n">iterations</span> <span class="o">&lt;</span> <span class="mi">50</span><span class="p">:</span>
            <span class="n">z</span> <span class="o">=</span> <span class="nf">complex_sqr</span><span class="p">(</span><span class="n">z</span><span class="p">)</span><span class="o">+</span><span class="n">c</span>
            <span class="n">iterations</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">pixels</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="o">-</span><span class="n">iterations</span><span class="o">*</span><span class="mf">0.02</span>


<span class="n">gui</span> <span class="o">=</span> <span class="n">ti</span><span class="p">.</span><span class="nc">GUI</span><span class="p">(</span><span class="sh">"</span><span class="s">Julia Set</span><span class="sh">"</span><span class="p">,</span> <span class="n">res</span><span class="o">=</span><span class="p">(</span><span class="n">n</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1000000</span><span class="p">):</span>
    <span class="nf">paint</span><span class="p">(</span><span class="n">i</span><span class="o">*</span><span class="mf">0.03</span><span class="p">)</span>
    <span class="c1"># Launch kernels. After this, tensors can only be accessed
</span>    <span class="c1"># Any allocation is not allowed after first launch
</span>    <span class="n">gui</span><span class="p">.</span><span class="nf">set_image</span><span class="p">(</span><span class="n">pixels</span><span class="p">)</span>
    <span class="n">gui</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <h1 id="useful-operations">Useful operations</h1> <p><strong>Math operations:</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ti</span><span class="p">.(</span><span class="n">sin</span><span class="p">,</span> <span class="n">cos</span><span class="p">,</span> <span class="n">asin</span><span class="p">,</span> <span class="n">acos</span><span class="p">,</span> <span class="nf">atan2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="nf">cast</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">data_type</span><span class="p">))</span>
<span class="n">ti</span><span class="p">.(</span><span class="n">sqrt</span><span class="p">,</span> <span class="n">floor</span><span class="p">,</span> <span class="n">ceil</span><span class="p">,</span> <span class="n">inv</span><span class="p">,</span> <span class="n">tan</span><span class="p">,</span> <span class="n">tanh</span><span class="p">,</span> <span class="n">exp</span><span class="p">,</span> <span class="n">log</span><span class="p">,</span> <span class="nf">random</span><span class="p">(</span><span class="n">data_type</span><span class="p">))</span>

<span class="nb">abs</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nf">max</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="p">...),</span> <span class="nf">min</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="p">...),</span> <span class="n">x</span><span class="o">**</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="o">/</span><span class="n">b</span><span class="p">,</span> <span class="n">x</span><span class="o">//</span><span class="n">b</span>
</code></pre></div></div> <p><strong>Matrix operations:</strong></p> <p>Differentiate element-wise product * and matrix product @.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">A</span><span class="o">*</span><span class="n">B</span>

<span class="n">A</span><span class="nd">@B</span>

<span class="n">A</span><span class="p">.(</span><span class="n">transpose</span><span class="p">,</span> <span class="n">inverse</span><span class="p">,</span> <span class="n">trace</span><span class="p">,</span> <span class="nf">determinant</span><span class="p">(</span><span class="nb">type</span><span class="p">),</span> <span class="n">normalized</span><span class="p">,</span> <span class="nf">cast</span><span class="p">(</span><span class="nb">type</span><span class="p">))</span>

<span class="n">R</span><span class="p">,</span> <span class="n">S</span> <span class="o">=</span> <span class="n">ti</span><span class="p">.</span><span class="nf">polar_decompose</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">ti</span><span class="p">.</span><span class="n">f32</span><span class="p">)</span> 
<span class="n">U</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="n">ti</span><span class="p">.</span><span class="nf">svd</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">ti</span><span class="p">.</span><span class="n">f32</span><span class="p">)</span> <span class="c1"># sigma is a 3*3 diagonal matrix
</span>
<span class="n">ti</span><span class="p">.</span><span class="nf">sin</span><span class="p">(</span><span class="n">A</span><span class="p">)</span><span class="o">/</span><span class="nf">cos</span><span class="p">(</span><span class="n">A</span><span class="p">)</span> <span class="c1">#element-wise
</span></code></pre></div></div> <p><strong>Note: polar decomposition</strong></p> <p>A matrix $A\in \mathbb{C}^{m\times n}$ with $m&gt;n$, polar decomposition is a factorization $A=UH$ where $U\in \mathbb{C}^{m\times n}$ has orthonormal columns and $H\in\mathbb{n\times n}$ is Hermitian positive semidefinite. This composition is a generalization of the polar representation $z=re^{i\theta}$ of a complex number, where $H$ corresponds to $r\geq 0$ and $U$ to $e^{i\theta}$. When A is real, H is symmetrix positive semidefinite. When m=n, U is a square unitary matrix.</p> <p><strong>Note: Singular Value Decomposition</strong></p> <p>TODO</p> <h1 id="parallel-for-loops">Parallel for-loops</h1> <p>For loops in Taichi have two forms:</p> <ul> <li><strong>Range-for loops</strong>, automatically <strong>parallelized</strong> when used at the outermost scope.</li> <li><strong>Struct-for loops</strong>, iterates over (sparse) tensor elements.</li> </ul> <h2 id="atomic-operations">Atomic operations</h2> <p>An atomic operation is an operation that will always be executed <strong>without any other process being able to read or change state</strong> that is read or changed during the operation</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">total</span> <span class="o">=</span> <span class="n">ti</span><span class="p">.</span><span class="nf">field</span><span class="p">(</span><span class="n">dt</span> <span class="o">=</span> <span class="n">ti</span><span class="p">.</span><span class="n">f32</span><span class="p">,</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">())</span>

<span class="nd">@ti.kernel</span>
<span class="k">def</span> <span class="nf">sum</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">x</span><span class="p">:</span>
        <span class="c1"># Approach 1
</span>        <span class="n">total</span><span class="p">[</span><span class="bp">None</span><span class="p">]</span> <span class="o">+=</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="c1"># Correct, Automatically atomic
</span>
        <span class="c1">#Approach 2
</span>        <span class="n">ti</span><span class="p">.</span><span class="nf">atomic_add</span><span class="p">(</span><span class="n">total</span><span class="p">[</span><span class="bp">None</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="c1"># Correct
</span>
        <span class="c1">#Approach 3
</span>        <span class="n">total</span><span class="p">[</span><span class="bp">None</span><span class="p">]</span> <span class="o">=</span> <span class="n">total</span><span class="p">[</span><span class="bp">None</span><span class="p">]</span> <span class="o">+</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="c1"># Wrong, not atomic, may cause error in parralized calculation
</span></code></pre></div></div> <h1 id="phases-of-a-taichi-program">Phases of a Taichi Program</h1> <ul> <li>Initialization: <em>ti.init(…)</em></li> <li>Tensor allocation: <em>ti.field, ti.Vector.field, ti.Matrix.field</em></li> <li>Computation (launch kernels, access tensors in Python-scope)</li> <li>Optional: restart the Taichi system (clear memory, destory all variables and kernels): ti.reset()</li> </ul> <p>For now, <strong>after the first kernel launch or tensor access in Python-scope, no more tensor allocation is allowed</strong>.</p> <h1 id="debug-mod">Debug Mod</h1> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ti</span><span class="p">.</span><span class="nf">init</span><span class="p">(</span><span class="n">debug</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="n">arch</span> <span class="o">=</span> <span class="n">ti</span><span class="p">.</span><span class="n">cpu</span><span class="p">)</span>
</code></pre></div></div> <p>CPU only, much slower.</p> <h1 id="export-mp4-and-gif">Export Mp4 and GIF</h1> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ti</span><span class="p">.</span><span class="nf">imwrite</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
<span class="n">ti</span> <span class="n">video</span> <span class="o">-</span><span class="n">f</span> <span class="mi">24</span>
<span class="n">ti</span> <span class="n">video</span> <span class="o">-</span><span class="n">f</span> <span class="mi">60</span>
<span class="n">ti</span> <span class="n">gif</span> <span class="o">-</span><span class="n">i</span> <span class="nb">input</span><span class="p">.</span><span class="n">mp4</span>
</code></pre></div></div>]]></content><author><name></name></author><category term="blog"/><category term="note"/><summary type="html"><![CDATA[Taichi is a high-performance language for computer graphics, and the creator of Taichi set up a tutorial course for it. This post is a record of some simple notes of Taichi.]]></summary></entry><entry><title type="html">Review: Return of the Obra Dinn</title><link href="https://yoharol.github.io/blog/2019/Review-Return-of-the-Obra-Dinn/" rel="alternate" type="text/html" title="Review: Return of the Obra Dinn"/><published>2019-12-24T00:00:00+00:00</published><updated>2019-12-24T00:00:00+00:00</updated><id>https://yoharol.github.io/blog/2019/Review%20-%20Return%20of%20the%20Obra%20Dinn</id><content type="html" xml:base="https://yoharol.github.io/blog/2019/Review-Return-of-the-Obra-Dinn/"><![CDATA[<p>Intellectual gameplay and emotional storytelling always contradict with each other, but not for Lucas Pope’s games. <em>Return of the Obra Dinn</em> performs an immersive game experience with solid game mechanics, and also beautifully crafted narratives.</p> <p>To analyze Lucas’s great work, we need to locate where traditional storytelling and game mechanics collide. Robert McKee in his book <em>STORY</em> describes the substance of story as a progression of gaps. Story is born in the gap where protagonist’s expectation and result given by the world split. After the protagonist takes action, whether the result is positive or not, the writer will push the story into the next gap with greater conflict and greater risk, force more difficult and risk-taking action. Surprisingly, we can perfectly replace protagonist with player, writer with game designer. What’s different is, Game designers no longer design progression of gaps. Instead, the gap area would be replaced by a set of rules, a well-ordered system that defines how players take action based on expectation and get results, which is game mechanics(① diagram below). Comparing to the preset series of gaps in traditional stories, the gap of a game combine expectation and result into a unified system that approachable to the player.</p> <div style="text-align: center"><img src="/img/blogs/obradinn.PNG" width="500"/> </div> <p>When games integrate storytelling into gameplay, serious conflicts happen. Story line is based on preset gaps progression, leaves no place for game mechanics. For most games, the player can control the protagonist and take action(② diagram above), until they reach a critical point, then the game gives a result, like a piece of cutscene, then pushes the story and the player into the next gap. For branching narrative games like Detroit: Become Human, player’s action only decide which gap to go next, but players still tend to approach the predetermined best ending. In my mind that’s how interactive storytelling works.</p> <p>With the same framework, how Return of the Obra Dinn outperforms others? Step 1, push storytelling out of the gap by only picking necessary materials of the story and transform them into a representation system. Step 2, bring game mechanics back to the gap by setting tools and rules, to make representations approachable and playable to the player.</p> <p>The world of Obra Dinn is a merchant ship with corpses and skeletons. All information of 60 crew members on this ship is compressed into a log book composed of manifest, a crew list and hand-drawn sketches. The fate of each crew is simplified into a single descriptive sentence and only the death moment. After the whole story is torn into pieces and embodied by corpses spread on the ship, the player is given a magical watch. Encountered with every corpse, the player has a pocket watch to trigger a flashback to the frozen death moment. Lucas Pope transforms narratives to interactable objects, systematizes them with a set of interaction methods and rules, that’s his magical tricks.</p> <p>Similar operations are also performed in Lucas’s previous game Papers Please, that all information of every citizen is com-pressed into a one-page passport and other several supporting paperwork. As the immigration officer, the player is not allowed to freely communicate with others, and their only job is to allow immigrant to pass through or not. These limitations and barriers are Lucas Pope’s true cleverness to change player’s role from tradition, and these limitations are the gap Lucas creates to leave space for game mechanics.</p> <p>Most games are behaviorists with typical pattern composed of stimulus-response, award and reinforcement. Whereas Cognitive Science has rejected behaviorism since fifty years ago, that humans have innate talents to prepare them for complex information and representations. Humans create language, diagrams and documents, all these representation systems and develop strong skills to handle them, but they are always forgotten by game designers. Lucas Pope’s games don’t have much traditional game ‘behavior’ that he casts the player as worker, but they can still create immersive experiences, because he utilizes human’s pre-existing skills like cross-referencing, memorizing, logical analyzing and deducing rather than teaching them new gaming techniques. That’s why he’s games sound too serious, too arduous, but still charming and captivating. His games are great enlightenment to the game field, especially for serious and experimental games.</p>]]></content><author><name></name></author><category term="blog"/><category term="review"/><summary type="html"><![CDATA[Intellectual gameplay and emotional storytelling always contradict with each other, but not for Lucas Pope’s games. Return of the Obra Dinn performs an immersive game experience with solid game mechanics, and also beautifully crafted narratives.]]></summary></entry><entry><title type="html">Game: Turn on the Lights</title><link href="https://yoharol.github.io/blog/2019/project-5/" rel="alternate" type="text/html" title="Game: Turn on the Lights"/><published>2019-10-14T00:00:00+00:00</published><updated>2019-10-14T00:00:00+00:00</updated><id>https://yoharol.github.io/blog/2019/project-5</id><content type="html" xml:base="https://yoharol.github.io/blog/2019/project-5/"><![CDATA[<p>A 2D pixel horror game made in 4 days for Brackeys Jam.</p> <center style="font-size:24px"> <strong>Role:</strong> Individual developer<br/> <strong>Team size:</strong> 1<br/> <strong>Project duration:</strong> 4 days<br/> </center> <p><strong>What’s right</strong>:</p> <ul> <li>Used Unity shader to built a unique art style and could be reused for other projects</li> <li>Get lots of positive comments, also YouTube videos uploaded by players</li> <li>Good game feeling as a pixel-art horror game</li> </ul> <p><strong>What’s wrong:</strong></p> <ul> <li>Bad sound design</li> <li>Had many plans for further development but end up with no progress</li> </ul> <p><strong>Lessons learned</strong></p> <ul> <li>Play-test is important, but play-test by the designer himself is a terrible idea, especially for horror games</li> <li>Long-term projects require iteration, playtest and progress management, but it’s really hard for individual development</li> </ul> <h2 id="abstract">Abstract</h2> <p><em>Turn on the Lights</em> is a game made individually in 4 days for Community Jam. It made up to top 20 popular games on itch.io for 3 days. It’s is a 2D horror game published on <a href="https://inamika.itch.io/turn-on-the-lights" target="_blank">itch.io</a> with multiple playthrough videos uploaded by players in comments.</p> <p>I built a screen tone pixel-art style for this game. The banner of this website is an example rendered with the same shader.</p> <div style="text-align: center"><img src="/img/portfolio/shader.gif" width="500"/> </div> <p>Sounds, program and sprites of this game are all made by myself originally.</p>]]></content><author><name></name></author><category term="works"/><category term="game"/><summary type="html"><![CDATA[A 2D pixel horror game made in 4 days for Brackeys Jam.]]></summary></entry></feed>